{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy1MY07gy3nc",
        "outputId": "fce2c21e-e67a-4378-8493-21a2066a4dc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import tempfile\n",
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kq4e3rSy-WC",
        "outputId": "38a3fcd0-1a1e-4268-db7c-a3e2e9b1c803"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â€¢ Using TensorFlow Version: 2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Add TensorFlow Serving Distribution URI as a Package Source**"
      ],
      "metadata": {
        "id": "3N4HTaLSzsHj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kita akan menggunakan TensorFlow Serving menggunakana `Aptitude` (the default Debian package manager) Karena Colab runs di Debian environment.\n",
        "\n",
        "Sebelum kita dapat menginstal Tensorflow Serving, kita perlu menambahkan paket `tensorflow-model-server` ke dalam daftar paket yang diketahui Aptitude. Perhatikan bahwa kita running sebagai root.\n",
        "\n",
        "**Note**: Notebook ini menjalankan tensorflow serving secara native, tetapi [Anda juga dapat menjalankannya dalam Docker Container](https://www.tensorflow.org/tfx/serving/docker?hl=id), yang merupakan salah satu cara termudah mulai menggunakan tensorflow serving. Docker engine tersedia untuk berbagai platform `Linux`,`Windows`, dan `Mac`."
      ],
      "metadata": {
        "id": "KsM233mLz3QM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the same as you would do from your command line, but without the [arch=amd64], and no sudo\n",
        "# You would instead do:\n",
        "# echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "# curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
        "\n",
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsoXPagzzuEq",
        "outputId": "5d56c3bb-ef4c-4ab5-c340-a732d5f9228c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "100  2943  100  2943    0     0  17201      0 --:--:-- --:--:-- --:--:-- 17311\n",
            "OK\n",
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:4 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,026 B]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:9 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [341 B]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,848 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,383 kB]\n",
            "Get:14 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [349 B]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,118 kB]\n",
            "Fetched 6,586 kB in 2s (3,791 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mhttp://storage.googleapis.com/tensorflow-serving-apt/dists/stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install TensorFlow Serving**\n",
        "\n",
        "Sekarang setelah paket Aptitude telah diperbarui, kita dapat menggunakan perintah `apt-get` untuk menginstal Tensorflow model server."
      ],
      "metadata": {
        "id": "zazFfuJu1zaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install tensorflow-model-server"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPp1IxS42N9m",
        "outputId": "1531ef9f-403d-42bf-ed71-309b8687ff71"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 650 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.16.1 [650 MB]\n",
            "Fetched 650 MB in 6s (101 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.16.1_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.16.1) ...\n",
            "Setting up tensorflow-model-server (2.16.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Dataset**\n",
        "\n",
        "Sekarang, kita akan membuat sebuah dataset sederhana yang mengekspresikan hubungan tersebut:\n",
        "\n",
        "*y* = 2x - 1\n",
        "\n",
        "antara inputs (`xs`) dan outputs (`ys`)."
      ],
      "metadata": {
        "id": "8ZJu3WDk2VT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
      ],
      "metadata": {
        "id": "UcT6ulnY29ta"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build dan Train the Model**\n",
        "\n",
        "Kita akan menggunakan model yang paling sederhana untuk contoh ini. Karena kita akan train model kita untuk `500 epochs`, untuk menghindari clutter/kekacauan pada layar, kita akan menggunakan argumen `verbose = 0` dalam metode `fit.` Mode Verbosity bisa:\n",
        "\n",
        "\n",
        "*   `0`: Silent.\n",
        "*   `1`: Progress bar.\n",
        "*   `2`: one line per epoch.\n",
        "\n",
        "Sebagai catatan tambahan, kami harus menyebutkan bahwa karena progress bar tidak terlalu berguna ketika masuk ke sebuah file, maka `verbose = 2` direkomendasikan ketika tidak berjalan secara interaktif (misalnya, dalam production environment).\n",
        "\n"
      ],
      "metadata": {
        "id": "FiNvyMIo3bIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([tf.keras.layers.Dense(units=1, input_shape=[1])])\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='mean_squared_error')\n",
        "\n",
        "history = model.fit(xs, ys, epochs=500, verbose=0)\n",
        "\n",
        "print(\"Finished training the model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMHpptc142VB",
        "outputId": "ebc0f039-232e-436c-c9b0-3ee52f8ea9ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished training the model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test the Model**\n",
        "\n",
        "Setelah model di train, kita dapat mengetestnya. Jika kita memberi nilai `10`, kita akan mendapatkan nilai yang sangat mendekati `19`."
      ],
      "metadata": {
        "id": "kFBNBBLn47ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict([10.0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI4EIBuq5TzU",
        "outputId": "e37630e6-083f-4114-e693-5b6987eed1c6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 128ms/step\n",
            "[[18.981976]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save the Model**\n",
        "\n",
        "untuk meload model yang telah dilatih ke dalam tensorflow serving, pertama-tama kita harus menyimpannya ke dalam format `SavedModel`. Ini akan membuat file protobuf dalam hirarki direktori yang terdefinisi dengan baik, dan akan menyertakan `nomor versi`.\n",
        "\n",
        "Tensorflow Serving memungkinkan kita memilih versi model yang mana, atau \"Servable\" yang ingin kita gunakan ketika membuat inference requests/permintaan inferensi. Setiap versi akan di ekspor ke Sub-direktori yang berbeda di bawah jalur/path yang diberikan."
      ],
      "metadata": {
        "id": "nKGXts0S5aDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIR = tempfile.gettempdir()\n",
        "\n",
        "version = 1\n",
        "\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "\n",
        "if os.path.isdir(export_path):\n",
        "    print('\\nAlready saved a model, cleaning up\\n')\n",
        "    !rm -r {export_path}\n",
        "\n",
        "model.save(export_path, save_format=\"tf\")\n",
        "\n",
        "print('\\nexport_path = {}'.format(export_path))\n",
        "!ls -l {export_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkF0s4GL6nCf",
        "outputId": "a5a7ad74-eff0-454f-b77b-3f6d937885c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "export_path = /tmp/1\n",
            "total 60\n",
            "drwxr-xr-x 2 root root  4096 May 17 14:17 assets\n",
            "-rw-r--r-- 1 root root    55 May 17 14:17 fingerprint.pb\n",
            "-rw-r--r-- 1 root root  4422 May 17 14:17 keras_metadata.pb\n",
            "-rw-r--r-- 1 root root 39579 May 17 14:17 saved_model.pb\n",
            "drwxr-xr-x 2 root root  4096 May 17 14:17 variables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Examine Your Saved Model**\n",
        "\n",
        "Kita akan menggunakan command line utility `saved_model_cli` untuk melihat `MetaGraphDefs` dan `SignatureDefs` di SavedModel kita. Definisi signature didefinisikan oleh tensor input dan output, dan disimpan dengan default serving key."
      ],
      "metadata": {
        "id": "CbXlRHVS6wGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFgHhSHV7e7h",
        "outputId": "7e206475-27a6-4387-d6fa-999b250435bb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-17 14:21:36.125951: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-17 14:21:36.126033: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-17 14:21:36.132164: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-17 14:21:38.398960: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['dense_input'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: serving_default_dense_input:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "The MetaGraph with tag set ['serve'] contains the following ops: {'MergeV2Checkpoints', 'Identity', 'Pack', 'StatefulPartitionedCall', 'Const', 'MatMul', 'ReadVariableOp', 'ShardedFilename', 'BiasAdd', 'VarHandleOp', 'SaveV2', 'Placeholder', 'NoOp', 'Select', 'DisableCopyOnRead', 'StaticRegexFullMatch', 'StringJoin', 'RestoreV2', 'AssignVariableOp'}\n",
            "\n",
            "Concrete Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_input')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run the TensorFlow Model Server**\n",
        "\n",
        "Sekarang kita akan lunch/meluncurkan Tensorflow model server dengan bash script. Kita akan menggunakan argumen `--bg` untuk menjalankan script di latar belakang.\n",
        "\n",
        "Script kita akan mulai memrunning TensorFlow Serving dan memload model kita. Berikut adalah parameter yang akan digunakan:\n",
        "\n",
        "\n",
        "\n",
        "*   `rest_api_port`: Port yang akan anda gunakan untuk requests/permintaan\n",
        "*   `model_name`: Anda akan menggunakan ini dalam URL requests/permintaan anda. dan bisa apa saja.\n",
        "*   `model_base_path`: Ini adalah jalur/path ke direktori tempat anda menyimpan mode anda.\n",
        "\n",
        "Selain itu, karena variabel yang menunjuk ke direktori yang berisi model ada di Python, kita perlu cara untuk memberi tahu Bash script di mana menemukan model. Untuk melakukan ini, kita akan menulis nilai variabel Python ke environment variable menggunakan fungsi `os.environ`."
      ],
      "metadata": {
        "id": "yz5QQnsN7pqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
      ],
      "metadata": {
        "id": "i-qkwYUl9rHI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash --bg\n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=helloworld \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "metadata": {
        "id": "H3B557t99urp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sekarang kita dapat melihat `Log server`"
      ],
      "metadata": {
        "id": "8gxVuq5w9zyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tail server.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id44PM7f947g",
        "outputId": "d1a57fb4-d51d-4604-b978-123e12ffa6eb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "[evhttp_server.cc : 250] NET_LOG: Entering the event loop ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create JSON Object with Test Data**\n",
        "\n",
        "Kita sekarang siap untuk membangun JSON object dengan beberapa data sehingga kita dapat membuat beberapa inferences/kesimpulan. Kita akan menggunakan dan sebagai test data kita."
      ],
      "metadata": {
        "id": "VyX_Uk329_rH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xs = np.array([[9.0], [10.0]])\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": xs.tolist()})\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_Ct6SLz-Yqg",
        "outputId": "aa0d4d10-ba5c-452c-b6eb-8328be9e1c27"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"signature_name\": \"serving_default\", \"instances\": [[9.0], [10.0]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Make Inference Request**\n",
        "\n",
        "Terakhir, kita dapat membuat requests/permintaan inference dan mendapatkan inferencenya kembali. Kita akan mengirimkan permintaan prediksi sebagai POST ke titik akhir REST server kita, dan meneruskannya dengan test data kita. Kita akan meminta server kita untuk memberikan versi terbaru dari model kita tanpa menentukan versi tertentu. Responnya akan berupa JSON yang berisi prediksi."
      ],
      "metadata": {
        "id": "1FIZD35R-dku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if this cell fails execution because of an \"...Failed to establish a new connection...\" error,\n",
        "# try replacing in the link below 'localhost' with '127.0.0.1'\n",
        "\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://localhost:8501/v1/models/helloworld:predict', data=data, headers=headers)\n",
        "\n",
        "print(json_response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiTnHlTh_Van",
        "outputId": "56bea16b-d034-4731-ee68-b63805e8be89"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"predictions\": [[16.9845886], [18.9819756]\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kita juga dapat melihat prediksi secara langsung dengan memuat nilai untuk kunci prediksi."
      ],
      "metadata": {
        "id": "uLCuCsxz_dL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = json.loads(json_response.text)['predictions']\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TceMb9m_YIR",
        "outputId": "1e47ec6e-e743-46f0-98f2-9d08f8e53348"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[16.9845886], [18.9819756]]\n"
          ]
        }
      ]
    }
  ]
}